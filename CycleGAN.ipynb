{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1711541021675,
     "user": {
      "displayName": "Guoshun Yu",
      "userId": "03697553051143014514"
     },
     "user_tz": -480
    },
    "id": "8621977836a5935",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1711541021675,
     "user": {
      "displayName": "Guoshun Yu",
      "userId": "03697553051143014514"
     },
     "user_tz": -480
    },
    "id": "f6e279433ffedc34",
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:24.948185Z",
     "start_time": "2024-04-06T10:54:24.942055Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channel: int, out_channel=256):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            ConvolutionalBlock(in_channel, out_channel, is_activation=True, kernel_size=3, padding=1),\n",
    "            ConvolutionalBlock(in_channel, out_channel, is_activation=False, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1711541021675,
     "user": {
      "displayName": "Guoshun Yu",
      "userId": "03697553051143014514"
     },
     "user_tz": -480
    },
    "id": "f6e279433ffedc34",
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:24.959691Z",
     "start_time": "2024-04-06T10:54:24.950204Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvolutionalBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channel: int,\n",
    "            out_channel: int,\n",
    "            kernel_size: int,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            is_downsample=True,\n",
    "            is_activation=True,\n",
    "            out_padding=1,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if is_downsample:\n",
    "            self.main = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding, **kwargs),\n",
    "                nn.InstanceNorm2d(out_channel),\n",
    "            )\n",
    "            if is_activation:\n",
    "                self.main.append(nn.ReLU(inplace=True))\n",
    "            else:\n",
    "                self.main.append(nn.Identity())\n",
    "        else:\n",
    "            self.main = nn.Sequential(\n",
    "                nn.ConvTranspose2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                   output_padding=out_padding,\n",
    "                                   **kwargs),\n",
    "                nn.InstanceNorm2d(out_channel)\n",
    "            )\n",
    "            if is_activation:\n",
    "                self.main.append(nn.ReLU(inplace=True))\n",
    "            else:\n",
    "                self.main.append(nn.Identity())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1711541021675,
     "user": {
      "displayName": "Guoshun Yu",
      "userId": "03697553051143014514"
     },
     "user_tz": -480
    },
    "id": "f6e279433ffedc34",
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:24.974499Z",
     "start_time": "2024-04-06T10:54:24.961706Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channel=3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        channel = [64, 128, 256, 128, 64, 3]\n",
    "        self.layers_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channel, channel[0], kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\"),\n",
    "            nn.InstanceNorm2d(channel[0]),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layers_2 = nn.ModuleList(\n",
    "            [ConvolutionalBlock(channel[0], channel[1], kernel_size=3, stride=2, padding=1, is_downsample=True,\n",
    "                                is_activation=True),\n",
    "             ConvolutionalBlock(channel[1], channel[2], kernel_size=3, stride=2, padding=1, is_downsample=True,\n",
    "                                is_activation=True)]\n",
    "        )\n",
    "        self.layers_3 = nn.Sequential(\n",
    "            *[ResidualBlock(channel[2]) for _ in range(9)]\n",
    "        )\n",
    "        self.layers_4 = nn.ModuleList(\n",
    "            [ConvolutionalBlock(channel[2], channel[3], kernel_size=3, stride=2, padding=1, is_downsample=False,\n",
    "                                is_activation=True, out_padding=1),\n",
    "             ConvolutionalBlock(channel[3], channel[4], kernel_size=3, stride=2, padding=1, is_downsample=False,\n",
    "                                is_activation=True, out_padding=1)]\n",
    "        )\n",
    "        self.layers_5 = nn.Sequential(\n",
    "            nn.Conv2d(channel[4], channel[5], kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers_1(x)\n",
    "        for layer in self.layers_2:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.layers_3(x)\n",
    "\n",
    "        for layer in self.layers_4:\n",
    "            x = layer(x)\n",
    "        return torch.tanh(self.layers_5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1711541021675,
     "user": {
      "displayName": "Guoshun Yu",
      "userId": "03697553051143014514"
     },
     "user_tz": -480
    },
    "id": "8edf7ba5d7e9ceb8",
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:24.985552Z",
     "start_time": "2024-04-06T10:54:24.977511Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channel=3):\n",
    "        super().__init__()\n",
    "\n",
    "        channels = [64, 128, 256, 512]\n",
    "\n",
    "        def ConvInstanceNormLeakyReLUBlock(\n",
    "                in_channel,\n",
    "                out_channel,\n",
    "                normalize=True,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                activation=None\n",
    "        ):\n",
    "            layers = nn.ModuleList(\n",
    "                [nn.Conv2d(\n",
    "                    in_channel,\n",
    "                    out_channel,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    bias=False if normalize else True)]\n",
    "            )\n",
    "\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_channel))\n",
    "\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True) if activation is None else activation)\n",
    "\n",
    "            return layers\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            *ConvInstanceNormLeakyReLUBlock(in_channel, channels[0], normalize=False),\n",
    "            *ConvInstanceNormLeakyReLUBlock(channels[0], channels[1]),\n",
    "            *ConvInstanceNormLeakyReLUBlock(channels[1], channels[2]),\n",
    "            *ConvInstanceNormLeakyReLUBlock(channels[2], channels[3], stride=1),\n",
    "            *ConvInstanceNormLeakyReLUBlock(channels[3], 1, normalize=False, stride=1, activation=nn.Sigmoid())\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:25.034842Z",
     "start_time": "2024-04-06T10:54:24.988562Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:25.045776Z",
     "start_time": "2024-04-06T10:54:25.035857Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, monet_dir, photo_dir, size=(256, 256), normalize=True):\n",
    "        super().__init__()\n",
    "\n",
    "        def get_img_list(path):\n",
    "            is_image_file = lambda x: any(x.endswith(extension) for extension in (['.jpg']))\n",
    "            return [x for x in os.listdir(path) if is_image_file(x)]\n",
    "\n",
    "        self.monet_dir = monet_dir\n",
    "        self.photo_dir = photo_dir\n",
    "        self.monet_idx = dict()\n",
    "        self.photo_idx = dict()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "        for i, fl in enumerate(get_img_list(self.monet_dir)):\n",
    "            self.monet_idx[i] = fl\n",
    "        for i, fl in enumerate(get_img_list(self.photo_dir)):\n",
    "            self.photo_idx[i] = fl\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        rand_idx = int(np.random.uniform(0, len(self.monet_idx.keys())))\n",
    "        photo_path = os.path.join(self.photo_dir, self.photo_idx[rand_idx])\n",
    "        monet_path = os.path.join(self.monet_dir, self.monet_idx[idx])\n",
    "        photo_img = Image.open(photo_path)\n",
    "        photo_img = self.transform(photo_img)\n",
    "        monet_img = Image.open(monet_path)\n",
    "        monet_img = self.transform(monet_img)\n",
    "        return photo_img, monet_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.monet_idx.keys()), len(self.photo_idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1711541021675,
     "user": {
      "displayName": "Guoshun Yu",
      "userId": "03697553051143014514"
     },
     "user_tz": -480
    },
    "id": "4a2be6688331b011",
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:26.360222Z",
     "start_time": "2024-04-06T10:54:25.047789Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:26.832723Z",
     "start_time": "2024-04-06T10:54:26.362234Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1711541021675,
     "user": {
      "displayName": "Guoshun Yu",
      "userId": "03697553051143014514"
     },
     "user_tz": -480
    },
    "id": "ac6ede346437f3aa",
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:26.867673Z",
     "start_time": "2024-04-06T10:54:26.836416Z"
    }
   },
   "outputs": [],
   "source": [
    "class config():\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    NUM_EPOCHS = 50\n",
    "    BATCH_SIZE = 5\n",
    "    NUM_WORKERS = 8\n",
    "    LEARNING_RATE = 2e-3\n",
    "    LMBDA = 10\n",
    "    ROOT_MONET = \"E:\\github\\CycleGAN\\data\\monet_jpg\"\n",
    "    ROOT_PHOTO = \"E:\\github\\CycleGAN\\data\\photo_jpg\"\n",
    "    COEF = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 80,
     "status": "ok",
     "timestamp": 1711541021675,
     "user": {
      "displayName": "Guoshun Yu",
      "userId": "03697553051143014514"
     },
     "user_tz": -480
    },
    "id": "ac6ede346437f3aa",
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:26.891245Z",
     "start_time": "2024-04-06T10:54:26.869683Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = MyDataset(config.ROOT_MONET, config.ROOT_PHOTO)\n",
    "loader = DataLoader(train_data, batch_size=config.BATCH_SIZE, num_workers=config.NUM_WORKERS, drop_last=True,\n",
    "                    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:26.896390Z",
     "start_time": "2024-04-06T10:54:26.892255Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, save_path):\n",
    "    torch.save(state, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:26.905867Z",
     "start_time": "2024-04-06T10:54:26.898400Z"
    }
   },
   "outputs": [],
   "source": [
    "class AvgStats(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.losses = []\n",
    "\n",
    "    def append(self, loss):\n",
    "        self.losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:26.925325Z",
     "start_time": "2024-04-06T10:54:26.906872Z"
    }
   },
   "outputs": [],
   "source": [
    "class CycleGAN():\n",
    "    def __init__(self):\n",
    "        self.m_reals = 0\n",
    "        self.m_fakes = 0\n",
    "        self.avg_g_loss = 0\n",
    "        self.avg_d_loss = 0\n",
    "\n",
    "        self.d_p = Discriminator()\n",
    "        self.d_m = Discriminator()\n",
    "        self.g_ptm = Generator()\n",
    "        self.g_mtp = Generator()\n",
    "\n",
    "        self.gen_stats = AvgStats()\n",
    "        self.desc_stats = AvgStats()\n",
    "\n",
    "        self.init_models()\n",
    "\n",
    "        self.opt_disc = optim.Adam(\n",
    "            list(self.d_m.parameters()) + list(self.d_p.parameters()),\n",
    "            lr=config.LEARNING_RATE,\n",
    "            betas=(0.5, 0.999),\n",
    "        )\n",
    "        self.opt_gen = optim.Adam(\n",
    "            list(self.g_ptm.parameters()) + list(self.g_mtp.parameters()),\n",
    "            lr=config.LEARNING_RATE,\n",
    "            betas=(0.5, 0.999),\n",
    "        )\n",
    "\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.mse = nn.MSELoss()\n",
    "\n",
    "        self.g_scaler = torch.cuda.amp.GradScaler()\n",
    "        self.d_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    def init_models(self):\n",
    "        self.d_p = self.d_p.to(config.DEVICE)\n",
    "        self.d_m = self.d_m.to(config.DEVICE)\n",
    "        self.g_ptm = self.g_ptm.to(config.DEVICE)\n",
    "        self.g_mtp = self.g_mtp.to(config.DEVICE)\n",
    "\n",
    "    def train(self, dataset):\n",
    "\n",
    "        for epoch in range(config.NUM_EPOCHS):\n",
    "\n",
    "            total_g_loss = 0\n",
    "            total_d_loss = 0\n",
    "\n",
    "            loop = tqdm(dataset, leave=True)\n",
    "\n",
    "            for idx, (monet, photo) in enumerate(loop):\n",
    "                monet = monet.to(config.DEVICE)\n",
    "                photo = photo.to(config.DEVICE)\n",
    "                \n",
    "                with torch.cuda.amp.autocast():\n",
    "                    self.opt_gen.zero_grad()\n",
    "                    \n",
    "                    id_monet = self.g_ptm(monet)\n",
    "                    id_photo = self.g_mtp(photo)\n",
    "                    id_monet_loss = self.l1(id_monet, monet) * config.LMBDA * config.COEF\n",
    "                    id_photo_loss = self.l1(id_photo, photo) * config.LMBDA * config.COEF\n",
    "                    id_loss = id_photo_loss + id_monet_loss\n",
    "                    \n",
    "                    fake_monet = self.g_ptm(photo)\n",
    "                    d_m_fake = self.d_m(fake_monet)\n",
    "                    loss_g_m = self.mse(d_m_fake, torch.ones_like(d_m_fake))\n",
    "                    \n",
    "                    fake_photo = self.g_mtp(monet)\n",
    "                    d_p_fake = self.d_p(fake_photo)                 \n",
    "                    loss_g_p = self.mse(d_p_fake, torch.ones_like(d_p_fake))\n",
    "                    \n",
    "                    loss_g = loss_g_m+loss_g_p\n",
    "\n",
    "                    cycle_monet = self.g_ptm(fake_photo)\n",
    "                    cycle_photo = self.g_mtp(fake_monet)\n",
    "                    cycle_photo_loss = self.l1(cycle_photo, photo)\n",
    "                    cycle_monet_loss = self.l1(cycle_monet, monet)\n",
    "\n",
    "                    g_loss = (\n",
    "                            loss_g\n",
    "                            + cycle_photo_loss * config.LMBDA\n",
    "                            + cycle_monet_loss * config.LMBDA\n",
    "                            + id_loss\n",
    "                    )\n",
    "\n",
    "                    total_g_loss += g_loss.item()\n",
    "\n",
    "                self.g_scaler.scale(g_loss).backward()\n",
    "                self.g_scaler.step(self.opt_gen)\n",
    "                self.g_scaler.update()\n",
    "\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    self.opt_disc.zero_grad()\n",
    "                    \n",
    "                    d_m_real = self.d_m(monet)\n",
    "                    d_m_fake = self.d_m(fake_monet.detach())\n",
    "                    self.m_reals += d_m_real.mean().item()\n",
    "                    self.m_fakes += d_m_fake.mean().item()\n",
    "                    d_m_real_loss = self.mse(d_m_real, torch.ones_like(d_m_real))\n",
    "                    d_m_fake_loss = self.mse(d_m_fake, torch.zeros_like(d_m_fake))\n",
    "                    d_m_loss = d_m_real_loss + d_m_fake_loss\n",
    "                    \n",
    "                    d_p_real = self.d_p(photo)\n",
    "                    d_p_fake = self.d_p(fake_photo.detach())\n",
    "                    d_p_real_loss = self.mse(d_p_real, torch.ones_like(d_p_real))\n",
    "                    d_p_fake_loss = self.mse(d_p_real, torch.zeros_like(d_p_fake))\n",
    "                    d_p_loss = d_p_real_loss + d_p_fake_loss\n",
    "\n",
    "                    d_loss = (d_m_loss + d_p_loss) / 2\n",
    "\n",
    "                    total_d_loss += d_loss.item()\n",
    "\n",
    "                self.d_scaler.scale(d_loss).backward()\n",
    "                self.d_scaler.step(self.opt_disc)\n",
    "                self.d_scaler.update()\n",
    "              \n",
    "                self.avg_d_loss = total_d_loss / dataset.__len__()\n",
    "                self.avg_g_loss = total_g_loss / dataset.__len__()\n",
    "\n",
    "                loop.set_postfix(m_real=self.m_reals / (idx + 1), m_fake=self.m_fakes / (idx + 1))\n",
    "\n",
    "            save_dict = {\n",
    "                'epoch': epoch + 1,\n",
    "                'g_mtp': self.g_mtp.state_dict(),\n",
    "                'g_ptm': self.g_ptm.state_dict(),\n",
    "                'd_m': self.d_m.state_dict(),\n",
    "                'd_p': self.d_p.state_dict(),\n",
    "                'optimizer_gen': self.opt_gen.state_dict(),\n",
    "                'optimizer_desc': self.opt_disc.state_dict()\n",
    "            }\n",
    "            save_checkpoint(save_dict, 'current.ckpt')\n",
    "\n",
    "            print(\"Epoch: (%d) | Generator Loss:%f | Discriminator Loss:%f\" % (epoch +\n",
    "                                                                               1, self.avg_g_loss, self.avg_d_loss))\n",
    "\n",
    "            self.gen_stats.append(self.avg_g_loss)\n",
    "            self.desc_stats.append(self.avg_d_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:27.428219Z",
     "start_time": "2024-04-06T10:54:26.927335Z"
    }
   },
   "outputs": [],
   "source": [
    "gan = CycleGAN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-06T10:54:27.437515Z",
     "start_time": "2024-04-06T10:54:27.429229Z"
    }
   },
   "outputs": [],
   "source": [
    "save_dict = {\n",
    "    'epoch': 0,\n",
    "    'g_mtp': gan.g_mtp.state_dict(),\n",
    "    'g_ptm': gan.g_ptm.state_dict(),\n",
    "    'd_m': gan.d_m.state_dict(),\n",
    "    'd_p': gan.d_p.state_dict(),\n",
    "    'optimizer_gen': gan.opt_gen.state_dict(),\n",
    "    'optimizer_desc': gan.opt_disc.state_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-06T10:54:27.438521Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                        | 0/60 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "gan.train(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.plot(gan.gen_stats.losses, 'r', label='Generator Loss')\n",
    "plt.plot(gan.desc_stats.losses, 'b', label='Descriminator Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "class PhotoDataset(Dataset):\n",
    "    def __init__(self, photo_dir, size=(256, 256), normalize=True):\n",
    "        super().__init__()\n",
    "\n",
    "        def get_img_list(path):\n",
    "            is_image_file = lambda x: any(x.endswith(extension) for extension in (['.jpg']))\n",
    "            return [x for x in os.listdir(path) if is_image_file(x)]\n",
    "\n",
    "        self.photo_dir = photo_dir\n",
    "        self.photo_idx = dict()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "        for i, fl in enumerate(get_img_list(self.photo_dir)):\n",
    "            self.photo_idx[i] = fl\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        photo_path = os.path.join(self.photo_dir, self.photo_idx[idx])\n",
    "        photo_img = Image.open(photo_path)\n",
    "        photo_img = self.transform(photo_img)\n",
    "        return photo_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.photo_idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "ph_ds = PhotoDataset(\"./kaggle/input/gan-getting-started/photo_jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "ph_dl = DataLoader(ph_ds, batch_size=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "!mkdir ./images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "trans = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def unnorm(img, mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]):\n",
    "    for t, m, s in zip(img, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "t = tqdm(ph_dl, leave=False, total=ph_dl.__len__())\n",
    "for i, photo in enumerate(t):\n",
    "    if i == 10:\n",
    "        break\n",
    "    with torch.no_grad():\n",
    "        pred_monet = gan.g_ptm(photo.to(\"cuda\")).cpu().detach()\n",
    "    pred_monet = unnorm(pred_monet)\n",
    "    img = trans(pred_monet[0]).convert(\"RGB\")\n",
    "    img.save(\"./images/\" + str(i + 1) + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": ".m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m119"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1475600,
     "sourceId": 21755,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
